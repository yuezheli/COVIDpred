{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COVID_prediction_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "chNdTN73FVMo"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import math\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LSTM\r\n",
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "# convert an array of values into a dataset matrix\r\n",
        "def create_dataset(dataset, look_back=1):\r\n",
        "    dataX, dataY = [], []\r\n",
        "    for i in range(len(dataset)-look_back-1):\r\n",
        "        a = dataset[i:(i+look_back), 0]\r\n",
        "        dataX.append(a)\r\n",
        "        dataY.append(dataset[i + look_back, 0])\r\n",
        "    return numpy.array(dataX), numpy.array(dataY)\r\n",
        "# fix random seed for reproducibility\r\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "V1U4DU3-FdV3",
        "outputId": "5ed2307c-f0ba-46dc-89f9-235f086341e2"
      },
      "source": [
        "# read in data\r\n",
        "\r\n",
        "dataframe = pd.read_csv('https://raw.githubusercontent.com/yuezheli/COVIDpred/main/CleanedData.csv', header = 0)\r\n",
        "\r\n",
        "dataframe['Date'] = pd.to_datetime(dataframe['Date'])\r\n",
        "\r\n",
        "\r\n",
        "# use Connecticut data \r\n",
        "ct = dataframe[dataframe['state'] == 'Connecticut']\r\n",
        "\r\n",
        "newconfirmed= np.zeros([len(ct)])\r\n",
        "newdeath = np.zeros([len(ct)])\r\n",
        "\r\n",
        "for i in range(len(ct)-1):\r\n",
        "    newconfirmed[i+1] = ct['confirmed'].iloc[i+1] - ct['confirmed'].iloc[i] \r\n",
        "    newdeath[i+1] = ct['death'].iloc[i+1] - ct['death'].iloc[i] \r\n",
        "\r\n",
        "ct['added confirmed'] = newconfirmed\r\n",
        "ct['added death'] = newdeath\r\n",
        "\r\n",
        "ct.set_index('Date', drop = True, inplace = True)\r\n",
        "\r\n",
        "ct.head()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>confirmed</th>\n",
              "      <th>death</th>\n",
              "      <th>state</th>\n",
              "      <th>added confirmed</th>\n",
              "      <th>added death</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Connecticut</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Connecticut</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Connecticut</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Connecticut</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Connecticut</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            confirmed  death        state  added confirmed  added death\n",
              "Date                                                                   \n",
              "2020-01-22          0      0  Connecticut              0.0          0.0\n",
              "2020-01-23          0      0  Connecticut              0.0          0.0\n",
              "2020-01-24          0      0  Connecticut              0.0          0.0\n",
              "2020-01-25          0      0  Connecticut              0.0          0.0\n",
              "2020-01-26          0      0  Connecticut              0.0          0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "M9FDk9zvVhaX",
        "outputId": "98cc682f-7b8b-4de5-e034-4a9ff9bc4bfd"
      },
      "source": [
        "dataset = pd.DataFrame(ct['added confirmed'], columns = ['added confirmed'])\r\n",
        "\r\n",
        "#dataset['days'] = range(len(ct))\r\n",
        "\r\n",
        "#dataset.reset_index(drop=True)\r\n",
        "\r\n",
        "dataset"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>added confirmed</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-01-22</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-23</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-24</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-25</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-01-26</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-02</th>\n",
              "      <td>2672.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-03</th>\n",
              "      <td>4751.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-04</th>\n",
              "      <td>1538.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-05</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-12-06</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>320 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            added confirmed\n",
              "Date                       \n",
              "2020-01-22              0.0\n",
              "2020-01-23              0.0\n",
              "2020-01-24              0.0\n",
              "2020-01-25              0.0\n",
              "2020-01-26              0.0\n",
              "...                     ...\n",
              "2020-12-02           2672.0\n",
              "2020-12-03           4751.0\n",
              "2020-12-04           1538.0\n",
              "2020-12-05              0.0\n",
              "2020-12-06              0.0\n",
              "\n",
              "[320 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Fz7iHIFVTcB"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\r\n",
        "dataset = scaler.fit_transform(dataset)\r\n"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSG80PWtZdX4"
      },
      "source": [
        "# split into train and test sets\r\n",
        "train_size = int(len(dataset) * 280/320)\r\n",
        "test_size = len(dataset) - train_size\r\n",
        "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUduFiNoZoOW"
      },
      "source": [
        "def LookBackSize(look_back = 4, train = train, test = test):\r\n",
        "  # reshape into X=t and Y=t+1\r\n",
        "  look_back = 4\r\n",
        "  trainX, trainY = create_dataset(train, look_back)\r\n",
        "  testX, testY = create_dataset(test, look_back)\r\n",
        "  # reshape input to be [samples, time steps, features]\r\n",
        "  trainX = numpy.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))\r\n",
        "  testX = numpy.reshape(testX, (testX.shape[0], testX.shape[1], 1))\r\n",
        "  \r\n",
        "  # create and fit the LSTM network\r\n",
        "  batch_size = 1\r\n",
        "  model = Sequential()\r\n",
        "  model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True, return_sequences=True))\r\n",
        "  model.add(LSTM(4, batch_input_shape=(batch_size, look_back, 1), stateful=True))\r\n",
        "  model.add(Dense(1))\r\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\r\n",
        "  \r\n",
        "  i = 0\r\n",
        "  while i < 150:\r\n",
        "    history = model.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\r\n",
        "    model.reset_states()\r\n",
        "    i = i + 1 \r\n",
        "    if history.history['loss'][0] < 0.001:\r\n",
        "      break\r\n",
        "      \r\n",
        "  # see final loss\r\n",
        "  print(history.history['loss'])\r\n",
        "\r\n",
        "  # make predictions\r\n",
        "  trainPredict = model.predict(trainX, batch_size=batch_size)\r\n",
        "  model.reset_states()\r\n",
        "  testPredict = model.predict(testX, batch_size=batch_size)\r\n",
        "\r\n",
        "  # invert predictions\r\n",
        "  trainPredict = scaler.inverse_transform(trainPredict)\r\n",
        "  trainY = scaler.inverse_transform([trainY])\r\n",
        "  testPredict = scaler.inverse_transform(testPredict)\r\n",
        "  testY = scaler.inverse_transform([testY])\r\n",
        "  \r\n",
        "  # print train score\r\n",
        "  # calculate root mean squared error\r\n",
        "  trainScore = mean_squared_error(trainY[0], trainPredict[:,0], squared=False)\r\n",
        "  print('Train Score: %.2f RMSE' % (trainScore))\r\n",
        "  return trainScore, model, history.history['loss']\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4g0FMopqh09C",
        "outputId": "c044816e-cb5f-4735-de0c-22ac4afe93b7"
      },
      "source": [
        "# model selection\r\n",
        "\r\n",
        "trainscores = []\r\n",
        "error = []\r\n",
        "\r\n",
        "for lookbacksize in range(7):\r\n",
        "  tmpscore, _, tmperr = LookBackSize(look_back = lookbacksize + 1)\r\n",
        "  trainscores.append(tmpscore)\r\n",
        "  error.append(tmperr)\r\n",
        "  del tmpscore, tmperr\r\n",
        "\r\n"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "275/275 - 3s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0041\n",
            "275/275 - 1s - loss: 0.0041\n",
            "275/275 - 1s - loss: 0.0040\n",
            "275/275 - 1s - loss: 0.0039\n",
            "275/275 - 1s - loss: 0.0038\n",
            "275/275 - 1s - loss: 0.0037\n",
            "275/275 - 1s - loss: 0.0035\n",
            "275/275 - 1s - loss: 0.0033\n",
            "275/275 - 1s - loss: 0.0032\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "[0.0022645052522420883]\n",
            "Train Score: 0.05 RMSE\n",
            "275/275 - 3s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0036\n",
            "275/275 - 1s - loss: 0.0037\n",
            "275/275 - 1s - loss: 0.0036\n",
            "275/275 - 1s - loss: 0.0036\n",
            "275/275 - 1s - loss: 0.0035\n",
            "275/275 - 1s - loss: 0.0034\n",
            "275/275 - 1s - loss: 0.0033\n",
            "275/275 - 1s - loss: 0.0032\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0022\n",
            "[0.0021963054314255714]\n",
            "Train Score: 0.05 RMSE\n",
            "275/275 - 3s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0036\n",
            "275/275 - 1s - loss: 0.0036\n",
            "275/275 - 1s - loss: 0.0035\n",
            "275/275 - 1s - loss: 0.0034\n",
            "275/275 - 1s - loss: 0.0033\n",
            "275/275 - 1s - loss: 0.0032\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "[0.002317830454558134]\n",
            "Train Score: 0.05 RMSE\n",
            "275/275 - 4s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0035\n",
            "275/275 - 1s - loss: 0.0035\n",
            "275/275 - 1s - loss: 0.0035\n",
            "275/275 - 1s - loss: 0.0034\n",
            "275/275 - 1s - loss: 0.0032\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0020\n",
            "275/275 - 1s - loss: 0.0019\n",
            "275/275 - 1s - loss: 0.0019\n",
            "275/275 - 1s - loss: 0.0019\n",
            "275/275 - 1s - loss: 0.0019\n",
            "275/275 - 1s - loss: 0.0019\n",
            "275/275 - 1s - loss: 0.0019\n",
            "[0.0019176695495843887]\n",
            "Train Score: 0.05 RMSE\n",
            "275/275 - 3s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0032\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "[0.0023312035482376814]\n",
            "Train Score: 0.05 RMSE\n",
            "275/275 - 4s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0039\n",
            "275/275 - 1s - loss: 0.0037\n",
            "275/275 - 1s - loss: 0.0036\n",
            "275/275 - 1s - loss: 0.0034\n",
            "275/275 - 1s - loss: 0.0033\n",
            "275/275 - 1s - loss: 0.0032\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "275/275 - 1s - loss: 0.0021\n",
            "[0.0021275707986205816]\n",
            "Train Score: 0.05 RMSE\n",
            "275/275 - 3s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0039\n",
            "275/275 - 1s - loss: 0.0040\n",
            "275/275 - 1s - loss: 0.0039\n",
            "275/275 - 1s - loss: 0.0037\n",
            "275/275 - 1s - loss: 0.0035\n",
            "275/275 - 1s - loss: 0.0033\n",
            "275/275 - 1s - loss: 0.0031\n",
            "275/275 - 1s - loss: 0.0030\n",
            "275/275 - 1s - loss: 0.0029\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0028\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0027\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0026\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0025\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0022\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0024\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "275/275 - 1s - loss: 0.0023\n",
            "[0.0022754387464374304]\n",
            "Train Score: 0.05 RMSE\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04872109053861772,\n",
              " 0.049096621521727425,\n",
              " 0.05053709711356614,\n",
              " 0.04528705213371255,\n",
              " 0.04858659660050341,\n",
              " 0.047025349073849025,\n",
              " 0.04972420501870226]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqXic6o6kxSN",
        "outputId": "1192a8d1-5af1-41eb-bb18-55ca2f7a337a"
      },
      "source": [
        "trainscores"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.04872109053861772,\n",
              " 0.049096621521727425,\n",
              " 0.05053709711356614,\n",
              " 0.04528705213371255,\n",
              " 0.04858659660050341,\n",
              " 0.047025349073849025,\n",
              " 0.04972420501870226]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVwGusZhoX_L"
      },
      "source": [
        "# model selected and prediction\r\n",
        "\r\n",
        "_, model,_ = LookBackSize(look_back = 4)\r\n",
        "\r\n",
        "trainPredict = model.predict(trainX, batch_size=batch_size)\r\n",
        "model.reset_states()\r\n",
        "testPredict = model.predict(testX, batch_size=batch_size)\r\n",
        "\r\n",
        "# invert predictions\r\n",
        "trainPredict = scaler.inverse_transform(trainPredict)\r\n",
        "testPredict = scaler.inverse_transform(testPredict)\r\n",
        "\r\n",
        "# shift train predictions for plotting\r\n",
        "trainPredictPlot = numpy.empty_like(dataset)\r\n",
        "trainPredictPlot[:, :] = numpy.nan\r\n",
        "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\r\n",
        "# shift test predictions for plotting\r\n",
        "testPredictPlot = numpy.empty_like(dataset)\r\n",
        "testPredictPlot[:, :] = numpy.nan\r\n",
        "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\r\n",
        "# plot baseline and predictions\r\n",
        "plt.plot(scaler.inverse_transform(dataset))\r\n",
        "plt.plot(trainPredictPlot)\r\n",
        "plt.plot(testPredictPlot)\r\n",
        "plt.show()\r\n",
        "\r\n",
        "\r\n",
        "print(mean_squared_error(testY[0], testPredict[:,0], squared=False)/np.mean( testY[0] ))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}